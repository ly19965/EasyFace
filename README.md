<div align="center">
  <img src="demo/modelscope.gif" width="40%" height="40%" />
</div>

<div align="center">

<!-- [![Documentation Status](https://readthedocs.org/projects/easy-cv/badge/?version=latest)](https://easy-cv.readthedocs.io/en/latest/) -->
[![license](https://img.shields.io/github/license/modelscope/modelscope.svg)](https://github.com/modelscope/modelscope/blob/master/LICENSE)
</div>


<h4 align="center">
    <a href=#EasyFace> ç‰¹æ€§ </a> |
    <a href=#å®‰è£…> å®‰è£… </a> |
    <a href=#å•æ¨¡å‹æ¨ç†> å•æ¨¡å‹æ¨ç†</a> | 
    <a href=#å•æ¨¡å‹è®­ç»ƒå’Œå¾®è°ƒ> å•æ¨¡å‹è®­ç»ƒ/å¾®è°ƒ</a> |
    <a href=#å•æ¨¡å‹é€‰å‹å’Œå¯¹æ¯”> å•æ¨¡å‹é€‰å‹/å¯¹æ¯”</a>  
    <!--- <a href=#äººè„¸è¯†åˆ«ç³»ç»Ÿå¤šæ¨¡å—ä¸€é”®é€‰å‹/å¯¹æ¯”> äººè„¸è¯†åˆ«ç³»ç»Ÿå¤šæ¨¡å—ä¸€é”®é€‰å‹/å¯¹æ¯”</a> -->
</h4>

## EasyFace

**EasyFace**æ—¨åœ¨å¿«é€Ÿé€‰å‹/äº†è§£/å¯¹æ¯”/ä½“éªŒäººè„¸ç›¸å…³sotaæ¨¡å‹ï¼Œä¾æ‰˜äº[**Modelscope**](https://modelscope.cn/home)å¼€å‘åº“å’Œ[**Pytorch**](https://pytorch.org)æ¡†æ¶ï¼ŒEasyFaceå…·æœ‰ä»¥ä¸‹ç‰¹æ€§:
- å¿«é€Ÿä½“éªŒ/å¯¹æ¯”/é€‰å‹Sotaçš„äººè„¸ç›¸å…³æ¨¡å‹, æ¶‰åŠäººè„¸æ£€æµ‹ï¼Œäººè„¸è¯†åˆ«ï¼Œäººè„¸å…³é”®ç‚¹ï¼Œäººè„¸è¡¨æƒ…è¯†åˆ«ï¼Œäººè„¸æ´»ä½“æ£€æµ‹ç­‰é¢†åŸŸï¼Œç›®å‰æ”¯æŒäººè„¸æ£€æµ‹ç›¸å…³sotaæ¨¡å‹ã€‚
- 5è¡Œä»£ç å³å¯è¿›è¡Œæ¨¡å‹æ¨ç†ï¼Œ10è¡Œä»£ç è¿›è¡Œæ¨¡å‹è®­ç»ƒ/Finetune, 20è¡Œä»£ç å¯¹æ¯”ä¸åŒæ¨¡å‹åœ¨è‡ªå»º/å…¬å¼€æ•°æ®é›†ä¸Šçš„ç²¾åº¦ä»¥åŠå¯è§†åŒ–ç»“æœã€‚
- åŸºäºç°æœ‰æ¨¡å‹å¿«é€Ÿæ­å»º[**åˆ›ç©ºé—´**](https://modelscope.cn/studios/damo/face_album/summary)åº”ç”¨ã€‚

## News ğŸ“¢

<!--- ğŸ”¥ **`2023-03-20`**ï¼šæ–°å¢DamoFRäººè„¸è¯†åˆ«æ¨¡å‹ï¼ŒåŸºäºVit Backbone å›´ç»•data-centricä»¥åŠpatch-level hard example  miningç­–ç•¥é‡æ–°è®¾è®¡äº†Transformer-based Small/Medium/Large äººè„¸è¯†åˆ«backboneï¼Œæ•ˆæœsotaï¼Œå·²releaseä¸åŒç®—åŠ›ä¸‹çš„sotaäººè„¸è¯†åˆ«ï¼Œå£ç½©äººè„¸è¯†åˆ«DamoFRæ¨¡å‹ï¼Œ[**paper**]() and [**project**]()ï¼›-->

ğŸ”¥ **`2023-03-10`**ï¼šæ–°å¢DamoFDï¼ˆICLR23ï¼‰äººè„¸æ£€æµ‹å…³é”®ç‚¹æ¨¡å‹ï¼ŒåŸºäºSCRFDæ¡†æ¶è¿›ä¸€æ­¥æœç´¢äº†FD-friendly backboneç»“æ„ã€‚ åœ¨0.5/2.5/10/34 GFlops VGAåˆ†è¾¨ç‡çš„ç®—åŠ›çº¦æŸæ¡ä»¶ä¸‹æ€§èƒ½å‡è¶…è¿‡SCRFDã€‚å…¶ä¸­æå‡ºçš„è½»é‡çº§çš„æ£€æµ‹å™¨DDSAR-0.5Gåœ¨VGAåˆ†è¾¨ç‡0.5GFlopsæ¡ä»¶ä¸‹WiderFaceä¸Šhardé›†ç²¾åº¦ä¸º71.03(è¶…è¿‡SCRFD 2.5ä¸ªç‚¹)ï¼Œæ¬¢è¿å¤§å®¶ä¸€é”®ä½¿ç”¨(æ”¯æŒè®­ç»ƒå’Œæ¨ç†)ï¼Œ[**paper**](https://openreview.net/forum?id=NkJOhtNKX91)ã€‚

ğŸ”¥  **`2023-03-10`**ï¼šæ–°å¢4ä¸ªäººè„¸æ£€æµ‹æ¨¡å‹ï¼ŒåŒ…æ‹¬DamoFDï¼ŒMogFaceï¼ŒRetinaFaceï¼ŒMtcnnã€‚

## æ”¯æŒæ¨¡å‹åˆ—è¡¨
**`å¯¹åº”æ¨¡å‹çš„æ¨ç†å’Œè®­ç»ƒå•å…ƒæµ‹è¯•æ”¾åœ¨face_projectç›®å½•ä¸‹`**

### æ¨ç†

ğŸ”¥ **`äººè„¸æ£€æµ‹`**
- DamoFDï¼ŒMogFaceï¼ŒRetinaFaceï¼ŒMtcnnã€‚
- ['damo/cv_ddsar_face-detection_iclr23-damofd', 'damo/cv_resnet101_face-detection_cvpr22papermogface',  'damo/cv_resnet50_face-detection_retinaface', 'damo/cv_manual_face-detection_mtcnn']

### è®­ç»ƒ
ğŸ”¥ **`äººè„¸æ£€æµ‹`**
- DamoFD
- ['damo/cv_ddsar_face-detection_iclr23-damofd']

## å®‰è£…
```
conda create --offline -n  EasyFace python=3.8
conda activate EasyFace
# pytorch >= 1.3.0
pip install torch==1.8.1+cu102  torchvision==0.9.1+cu102  --extra-index-url https://download.pytorch.org/whl/cu102
git clone https://github.com/ly19965/FaceMaas
cd FaceMaas
pip install -r requirements.txt
mim install mmcv-full
```

## å•æ¨¡å‹æ¨ç†
ä»æ”¯æŒæ¨ç†çš„æ¨¡å‹åˆ—è¡¨é‡Œé€‰æ‹©æƒ³ä½“éªŒçš„æ¨¡å‹, e.g.äººè„¸æ£€æµ‹æ¨¡å‹DamoFD_0.5g

### å•å¼ å›¾ç‰‡æ¨ç†
```python
import cv2
from modelscope.pipelines import pipeline
from modelscope.utils.constant import  Tasks

face_detection = pipeline(task=Tasks.face_detection, model='damo/cv_ddsar_face-detection_iclr23-damofd')
# æ”¯æŒ url image and abs dir image path
img_path = 'https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/face_detection2.jpeg' 
result = face_detection(img_path)

# æä¾›å¯è§†åŒ–ç»“æœ
from modelscope.utils.cv.image_utils import draw_face_detection_result
from modelscope.preprocessors.image import LoadImage
img = LoadImage.convert_to_ndarray(img_path)
cv2.imwrite('srcImg.jpg', img)
img_draw = draw_face_detection_result('srcImg.jpg', result)
import matplotlib.pyplot as plt
plt.imshow(img_draw)
```

### Miniå…¬å¼€æ•°æ®é›†æ¨ç†
```python
import os.path as osp
import cv2
import os
import numpy as np
from modelscope.msdatasets import MsDataset
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks
from modelscope.utils.cv.image_utils import voc_ap, image_eval,img_pr_info, gen_gt_info, dataset_pr_info, bbox_overlap

model_id = 'damo/cv_ddsar_face-detection_iclr23-damofd'
val_set = MsDataset.load('widerface_mini_train_val', namespace='ly261666', split='validation')#, download_mode=DownloadMode.FORCE_REDOWNLOAD)
img_base_path = next(iter(val_set))[1]
img_dir = osp.join(img_base_path, 'val_data')
img_gt = osp.join(img_base_path, 'val_label.txt')
gt_info = gen_gt_info(img_gt)
pred_info = {}
iou_th = 0.5
thresh_num = 1000
face_detection_func = pipeline(Tasks.face_detection, model=model_id)
count_face = 0
pr_curve = np.zeros((thresh_num, 2)).astype('float')
for img_name in os.listdir(img_dir):
    abs_img_name = osp.join(img_dir, img_name)
    result = face_detection_func(abs_img_name)
    pred_info = np.concatenate([result['boxes'], np.array(result['scores'])[:,np.newaxis]], axis=1)
    gt_box = np.array(gt_info[img_name])
    pred_recall, proposal_list = image_eval(pred_info, gt_box, iou_th)
    _img_pr_info, fp = img_pr_info(thresh_num, pred_info, proposal_list, pred_recall)
    pr_curve += _img_pr_info
    count_face += gt_box.shape[0]
    
pr_curve = dataset_pr_info(thresh_num, pr_curve, count_face)
propose = pr_curve[:, 0]
recall = pr_curve[:, 1]
for srecall in np.arange(0.1, 1.0001, 0.1):
    rindex = len(np.where(recall<=srecall)[0])-1
    rthresh = 1.0 - float(rindex)/thresh_num
    print('Recall-Precision-Thresh:', recall[rindex], propose[rindex], rthresh)
ap = voc_ap(recall, propose)
print('ap: %.5f, iou_th: %.2f'%(ap, iou_th))
```

## å•æ¨¡å‹è®­ç»ƒå’Œå¾®è°ƒ
ä»æ”¯æŒè®­ç»ƒçš„æ¨¡å‹åˆ—è¡¨é‡Œé€‰æ‹©æƒ³ä½“éªŒçš„æ¨¡å‹, e.g.äººè„¸æ£€æµ‹æ¨¡å‹DamoFD_0.5g

### è®­ç»ƒ

```python
import os
import tempfile
from modelscope.msdatasets import MsDataset
from modelscope.metainfo import Trainers
from modelscope.trainers import build_trainer
from modelscope.hub.snapshot_download import snapshot_download

model_id = 'damo/cv_ddsar_face-detection_iclr23-damofd'
ms_ds_widerface = MsDataset.load('WIDER_FACE_mini', namespace='shaoxuan')  # remove '_mini' for full dataset

data_path = ms_ds_widerface.config_kwargs['split_config']
train_dir = data_path['train']
val_dir = data_path['validation']

def get_name(dir_name):
    names = [i for i in os.listdir(dir_name) if not i.startswith('_')]
    return names[0]

train_root = train_dir + '/' + get_name(train_dir) + '/'
val_root = val_dir + '/' + get_name(val_dir) + '/'
cache_path = snapshot_download(model_id)
tmp_dir = tempfile.TemporaryDirectory().name
if not os.path.exists(tmp_dir):
    os.makedirs(tmp_dir)

def _cfg_modify_fn(cfg):
    cfg.checkpoint_config.interval = 1
    cfg.log_config.interval = 10
    cfg.evaluation.interval = 1
    cfg.data.workers_per_gpu = 1
    cfg.data.samples_per_gpu = 4
    return cfg

kwargs = dict(
    cfg_file=os.path.join(cache_path, 'DamoFD_lms.py'),
    work_dir=tmp_dir,
    train_root=train_root,
    val_root=val_root,
    total_epochs=1,  # run #epochs
    cfg_modify_fn=_cfg_modify_fn)

trainer = build_trainer(name=Trainers.face_detection_scrfd, default_args=kwargs)
trainer.train()
```

### æ¨¡å‹å¾®è°ƒ

```python
import os
import tempfile
from modelscope.msdatasets import MsDataset
from modelscope.metainfo import Trainers
from modelscope.trainers import build_trainer
from modelscope.hub.snapshot_download import snapshot_download
from modelscope.utils.constant import ModelFile

model_id = 'damo/cv_ddsar_face-detection_iclr23-damofd'
ms_ds_widerface = MsDataset.load('WIDER_FACE_mini', namespace='shaoxuan')  # remove '_mini' for full dataset

data_path = ms_ds_widerface.config_kwargs['split_config']
train_dir = data_path['train']
val_dir = data_path['validation']

def get_name(dir_name):
    names = [i for i in os.listdir(dir_name) if not i.startswith('_')]
    return names[0]

train_root = train_dir + '/' + get_name(train_dir) + '/'
val_root = val_dir + '/' + get_name(val_dir) + '/'
cache_path = snapshot_download(model_id)
tmp_dir = tempfile.TemporaryDirectory().name
pretrain_epochs = 640
ft_epochs = 1
total_epochs = pretrain_epochs + ft_epochs
if not os.path.exists(tmp_dir):
    os.makedirs(tmp_dir)

def _cfg_modify_fn(cfg):
    cfg.checkpoint_config.interval = 1
    cfg.log_config.interval = 10
    cfg.evaluation.interval = 1
    cfg.data.workers_per_gpu = 1
    cfg.data.samples_per_gpu = 4
    return cfg

kwargs = dict(
    cfg_file=os.path.join(cache_path, 'DamoFD_lms.py'),
    work_dir=tmp_dir,
    train_root=train_root,
    val_root=val_root,
    resume_from=os.path.join(cache_path, ModelFile.TORCH_MODEL_FILE),
    total_epochs=total_epochs,  # run #epochs
    cfg_modify_fn=_cfg_modify_fn)

trainer = build_trainer(name=Trainers.face_detection_scrfd, default_args=kwargs)
trainer.train()
```

## å•æ¨¡å‹é€‰å‹å’Œå¯¹æ¯”
```python
import os.path as osp
import cv2
import os
import numpy as np
from modelscope.msdatasets import MsDataset
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks
from modelscope.utils.cv.image_utils import voc_ap, image_eval,img_pr_info, gen_gt_info, dataset_pr_info, bbox_overlap

model_id_list = ['damo/cv_ddsar_face-detection_iclr23-damofd', 'damo/cv_resnet101_face-detection_cvpr22papermogface',  'damo/cv_resnet50_face-detection_retinaface', 'damo/cv_manual_face-detection_mtcnn'] 
val_set = MsDataset.load('widerface_mini_train_val', namespace='ly261666', split='validation')#, download_mode=DownloadMode.FORCE_REDOWNLOAD)
img_base_path = next(iter(val_set))[1]
img_dir = osp.join(img_base_path, 'val_data')
img_gt = osp.join(img_base_path, 'val_label.txt')
gt_info = gen_gt_info(img_gt)
pred_info = {}
iou_th = 0.5
thresh_num = 1000
count_face = 0
conf_th = 0.01
final_info = ""
pr_curve = np.zeros((thresh_num, 2)).astype('float')
for model_id in model_id_list:
    pr_curve = np.zeros((thresh_num, 2)).astype('float')
    count_face = 0
    if 'mtcnn' in model_id:
        face_detection_func = pipeline(Tasks.face_detection, model=model_id, conf_th=0.7) # Mtcnn only support high conf threshold
    elif 'damofd' in model_id:
        face_detection_func = pipeline(Tasks.face_detection, model=model_id) # Revise conf_th in DamoFD_lms.py
    else:
        face_detection_func = pipeline(Tasks.face_detection, model=model_id, conf_th=0.01)
    for idx, img_name in enumerate(os.listdir(img_dir)):
        print ('model_id: {}, inference img: {} {}/{}'.format(model_id, img_name, idx+1, len(os.listdir(img_dir))))
        abs_img_name = osp.join(img_dir, img_name)
        result = face_detection_func(abs_img_name)
        pred_info = np.concatenate([result['boxes'], np.array(result['scores'])[:,np.newaxis]], axis=1)
        gt_box = np.array(gt_info[img_name])
        pred_recall, proposal_list = image_eval(pred_info, gt_box, iou_th)
        _img_pr_info, fp = img_pr_info(thresh_num, pred_info, proposal_list, pred_recall)
        pr_curve += _img_pr_info
        count_face += gt_box.shape[0]
    
    pr_curve = dataset_pr_info(thresh_num, pr_curve, count_face)
    propose = pr_curve[:, 0]
    recall = pr_curve[:, 1]
    for srecall in np.arange(0.1, 1.0001, 0.1):
        rindex = len(np.where(recall<=srecall)[0])-1
        rthresh = 1.0 - float(rindex)/thresh_num
        print('Recall-Precision-Thresh:', recall[rindex], propose[rindex], rthresh)
    ap = voc_ap(recall, propose)
    result_info = 'model_id: {}, ap: {:.5f}, iou_th: {:.2f}'.format(model_id, ap, iou_th)
    print(result_info)
    final_info += result_info + '\n'
print("Overall Result:")
print(final_info)
```


<!--- ## äººè„¸è¯†åˆ«ç³»ç»Ÿå¤šæ¨¡å—ä¸€é”®é€‰å‹/å¯¹æ¯” -->






